"""
YOLOè°ƒè¯•å™¨ - åœ¨å›¾ç‰‡ä¸­æ ‡æ³¨YOLOè¯†åˆ«çš„æ‰€æœ‰ç‰©ä½“çš„æ–¹æ¡†å’Œç½®ä¿¡åº¦ç­‰ä¿¡æ¯
è¾“å…¥ï¼šå›¾ç‰‡æˆ–è§†é¢‘
è¾“å‡ºï¼šæ ‡æ³¨äº†YOLOè¯†åˆ«ç»“æœçš„å›¾ç‰‡

ä¼˜åŠ¿ï¼š
- é€Ÿåº¦å¿«ï¼ˆæ¯”Florenceå¿«5-10å€ï¼‰
- å¯ä»¥è‡ªå·±è®­ç»ƒæ¨¡å‹
- æ”¯æŒæœ¬åœ°æ¨¡å‹æ–‡ä»¶
- æ”¯æŒæ£€æµ‹æ‰€æœ‰ç‰©ä½“ç±»åˆ«
"""

import sys
import click
import cv2
import numpy as np
from pathlib import Path
from PIL import Image
from loguru import logger
import tqdm
import json
import time

try:
    from ultralytics import YOLO
except ImportError:
    logger.error("æœªå®‰è£… ultralytics åº“ï¼Œè¯·è¿è¡Œ: pip install ultralytics")
    sys.exit(1)


def load_yolo_model(model_path, device='cuda'):
    """åŠ è½½YOLOæ¨¡å‹"""
    model_path = Path(model_path)
    
    if not model_path.exists():
        logger.error(f"æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨: {model_path}")
        sys.exit(1)
    
    logger.info(f"åŠ è½½YOLOæ¨¡å‹: {model_path}")
    start_time = time.time()
    
    try:
        model = YOLO(str(model_path))
        
        # è®¾ç½®è®¾å¤‡
        if device == 'cuda':
            model.to('cuda')
        else:
            model.to('cpu')
        
        load_time = time.time() - start_time
        logger.info(f"æ¨¡å‹åŠ è½½å®Œæˆ ({load_time:.2f}ç§’)")
        
        # æ˜¾ç¤ºæ¨¡å‹ä¿¡æ¯
        if hasattr(model, 'names'):
            logger.info(f"æ£€æµ‹ç±»åˆ«: {model.names}")
        
        return model
        
    except Exception as e:
        logger.error(f"åŠ è½½æ¨¡å‹å¤±è´¥: {e}")
        sys.exit(1)


def detect_all_objects(image, model, conf_threshold=0.25, iou_threshold=0.45):
    """ä½¿ç”¨YOLOæ£€æµ‹æ‰€æœ‰ç‰©ä½“"""
    # YOLOæ¨ç†
    results = model.predict(
        image,
        conf=conf_threshold,
        iou=iou_threshold,
        verbose=False
    )
    
    detections = []
    
    if results and len(results) > 0:
        result = results[0]
        
        # è·å–æ£€æµ‹æ¡†
        if result.boxes is not None:
            boxes = result.boxes.xyxy.cpu().numpy()  # [x1, y1, x2, y2]
            confs = result.boxes.conf.cpu().numpy()   # ç½®ä¿¡åº¦
            classes = result.boxes.cls.cpu().numpy()  # ç±»åˆ«
            
            for box, conf, cls in zip(boxes, confs, classes):
                x1, y1, x2, y2 = box
                detections.append({
                    'bbox': [int(x1), int(y1), int(x2), int(y2)],
                    'confidence': float(conf),
                    'class': int(cls),
                    'class_name': model.names[int(cls)] if hasattr(model, 'names') else str(int(cls))
                })
    
    return detections


def create_mask_from_detections(image_shape, detections, max_bbox_percent=10.0, expand_pixels=5):
    """ä»YOLOæ£€æµ‹ç»“æœåˆ›å»ºmask"""
    height, width = image_shape[:2]
    mask = np.zeros((height, width), dtype=np.uint8)
    
    if not detections:
        return mask
    
    image_area = width * height
    
    logger.debug(f"åˆ›å»ºmaskï¼Œæ£€æµ‹åˆ° {len(detections)} ä¸ªç›®æ ‡")
    
    for i, det in enumerate(detections):
        x1, y1, x2, y2 = det['bbox']
        bbox_area = (x2 - x1) * (y2 - y1)
        area_percent = (bbox_area / image_area) * 100
        
        logger.debug(f"  [{i+1}] {det['class_name']} (conf: {det['confidence']:.2f})")
        logger.debug(f"      ä½ç½®: ({x1}, {y1}) -> ({x2}, {y2})")
        logger.debug(f"      å æ¯”: {area_percent:.2f}%")
        
        # æ£€æŸ¥å¤§å°é™åˆ¶
        if area_percent <= max_bbox_percent:
            # æ‰©å±•è¾¹ç•Œ
            x1 = max(0, x1 - expand_pixels)
            y1 = max(0, y1 - expand_pixels)
            x2 = min(width, x2 + expand_pixels)
            y2 = min(height, y2 + expand_pixels)
            
            mask[y1:y2, x1:x2] = 255
            logger.debug(f"      âœ… å·²æ·»åŠ åˆ°mask")
        else:
            logger.warning(f"      âŒ è·³è¿‡ï¼ˆè¶…è¿‡æœ€å¤§å æ¯” {max_bbox_percent}%ï¼‰")
    
    # åå¤„ç†ï¼šè†¨èƒ€å’Œæ¨¡ç³Š
    if np.any(mask > 0):
        kernel = np.ones((3, 3), np.uint8)
        mask = cv2.dilate(mask, kernel, iterations=1)
        mask = cv2.GaussianBlur(mask, (5, 5), 0)
    
    return mask


def annotate_image(image, detections, show_confidence=True, show_class_name=True):
    """åœ¨å›¾ç‰‡ä¸Šæ ‡æ³¨YOLOæ£€æµ‹ç»“æœ"""
    annotated = image.copy()
    
    if detections:
        for det in detections:
            x1, y1, x2, y2 = det['bbox']
            # ç»˜åˆ¶çŸ©å½¢æ¡†
            cv2.rectangle(annotated, (x1, y1), (x2, y2), (0, 0, 255), 2)
            
            # å‡†å¤‡æ ‡æ³¨æ–‡æœ¬
            label_parts = []
            if show_class_name:
                label_parts.append(det['class_name'])
            if show_confidence:
                label_parts.append(f"{det['confidence']:.2f}")
            
            if label_parts:
                label = " ".join(label_parts)
                # ç»˜åˆ¶æ–‡æœ¬èƒŒæ™¯
                (text_width, text_height), baseline = cv2.getTextSize(label, cv2.FONT_HERSHEY_SIMPLEX, 0.6, 2)
                cv2.rectangle(annotated, (x1, max(0, y1 - text_height - 5)), (x1 + text_width, y1), (0, 0, 255), -1)
                # ç»˜åˆ¶æ–‡æœ¬
                cv2.putText(annotated, label, (x1, max(0, y1 - 5)), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 2, cv2.LINE_AA)
    
    return annotated


def process_image(image_path, output_dir, model, conf_threshold, iou_threshold, max_bbox_percent, show_confidence=True, show_class_name=True):
    """å¤„ç†å•å¼ å›¾ç‰‡"""
    logger.info(f"å¤„ç†å›¾ç‰‡: {image_path}")
    
    # è¯»å–å›¾ç‰‡
    image = cv2.imread(str(image_path))
    if image is None:
        logger.error(f"æ— æ³•è¯»å–å›¾ç‰‡: {image_path}")
        return None
    
    image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
    
    # æ£€æµ‹æ‰€æœ‰ç‰©ä½“
    detections = detect_all_objects(image_rgb, model, conf_threshold, iou_threshold)
    
    # æ ‡æ³¨å›¾ç‰‡
    annotated_image = annotate_image(image, detections, show_confidence, show_class_name)
    
    # ä¿å­˜
    frame_name = image_path.stem
    output_image_path = output_dir / f"{frame_name}_annotated.png"
    output_dir.mkdir(exist_ok=True, parents=True)
    
    cv2.imwrite(str(output_image_path), annotated_image)
    logger.info(f"æ ‡æ³¨å›¾ç‰‡å·²ä¿å­˜åˆ°: {output_image_path}")
    
    # åˆ›å»ºmaskï¼ˆå¯é€‰ï¼‰
    mask = create_mask_from_detections(image_rgb.shape, detections, max_bbox_percent)
    masks_dir = output_dir / "masks"
    masks_dir.mkdir(exist_ok=True, parents=True)
    cv2.imwrite(str(masks_dir / f"{frame_name}.png"), mask)
    
    # ä¿å­˜æ£€æµ‹ä¿¡æ¯
    detection_info = {
        'frame': frame_name,
        'detections': detections,
        'mask_coverage': float(np.sum(mask > 127) / (mask.shape[0] * mask.shape[1]))
    }
    
    return detection_info


def process_video(video_path, output_dir, model, conf_threshold, iou_threshold, max_bbox_percent, 
                 show_confidence=True, show_class_name=True):
    """å¤„ç†è§†é¢‘"""
    logger.info(f"å¤„ç†è§†é¢‘: {video_path}")
    
    cap = cv2.VideoCapture(str(video_path))
    if not cap.isOpened():
        logger.error(f"æ— æ³•æ‰“å¼€è§†é¢‘: {video_path}")
        return
    
    # è·å–è§†é¢‘ä¿¡æ¯
    fps = cap.get(cv2.CAP_PROP_FPS)
    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
    
    logger.info(f"è§†é¢‘ä¿¡æ¯: {width}x{height}, {fps}fps, {total_frames}å¸§")
    
    # åˆ›å»ºè¾“å‡ºç›®å½•
    output_frames_dir = output_dir / "frames_annotated"
    output_frames_dir.mkdir(exist_ok=True, parents=True)
    
    masks_dir = output_dir / "masks"
    masks_dir.mkdir(exist_ok=True, parents=True)
    
    # å¤„ç†æ‰€æœ‰å¸§
    frame_count = 0
    detection_infos = []
    
    with tqdm.tqdm(total=total_frames, desc="é€å¸§æ£€æµ‹å’Œæ ‡æ³¨") as pbar:
        while cap.isOpened():
            ret, frame = cap.read()
            if not ret:
                break
            
            # æ£€æµ‹æ°´å°
            frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)# æ£€æµ‹æ‰€æœ‰ç‰©ä½“
            detections = detect_all_objects(
                frame_rgb, model, conf_threshold, iou_threshold
            )
            
            # æ ‡æ³¨å›¾ç‰‡
            annotated_frame = annotate_image(frame, detections, show_confidence, show_class_name)
            
            # ä¿å­˜æ ‡æ³¨åçš„å¸§
            frame_name = f"frame_{frame_count:06d}"
            cv2.imwrite(str(output_frames_dir / f"{frame_name}.png"), annotated_frame)
            
            # åˆ›å»ºmaskï¼ˆå¯é€‰ï¼‰
            mask = create_mask_from_detections(
                frame_rgb.shape, detections, max_bbox_percent
            )
            cv2.imwrite(str(masks_dir / f"{frame_name}.png"), mask)
            
            # è®°å½•æ£€æµ‹ä¿¡æ¯
            detection_info = {
                'frame': frame_name,
                'frame_index': frame_count,
                'num_detections': len(detections) if detections else 0,
                'mask_coverage': float(np.sum(mask > 127) / (mask.shape[0] * mask.shape[1]))
            }
            
            detection_infos.append(detection_info)
            
            frame_count += 1
            pbar.update(1)
    
    cap.release()
    
    # ä¿å­˜æ£€æµ‹ä¿¡æ¯
    with open(output_dir / "detection_info.json", 'w') as f:
        json.dump(detection_infos, f, indent=2)
    
    # ç»Ÿè®¡ä¿¡æ¯
    logger.info(f"\nâœ… å®Œæˆï¼å…±å¤„ç† {frame_count} å¸§")
    logger.info(f"ğŸ“ æ ‡æ³¨å¸§ä¿å­˜åˆ°: {output_frames_dir}")
    logger.info(f"ğŸ“ Maskä¿å­˜åˆ°: {masks_dir}")
    
    # è¾“å‡ºç»Ÿè®¡
    coverages = [info['mask_coverage'] for info in detection_infos]
    avg_coverage = sum(coverages) / len(coverages) if coverages else 0
    
    logger.info(f"ğŸ“Š æ£€æµ‹ç»Ÿè®¡:")
    logger.info(f"  å¹³å‡maskè¦†ç›–: {avg_coverage*100:.2f}%")
    
    num_detections = [info['num_detections'] for info in detection_infos]
    unique_counts = set(num_detections)
    
    if len(unique_counts) > 1:
        logger.warning(f"  âš ï¸  æ£€æµ‹æ•°é‡ä¸ä¸€è‡´:")
        for count in sorted(unique_counts):
            frames_with_count = sum(1 for n in num_detections if n == count)
            logger.warning(f"     {count}ä¸ªç›®æ ‡: {frames_with_count}å¸§")
    else:
        logger.info(f"  âœ… æ‰€æœ‰å¸§æ£€æµ‹ä¸€è‡´: {list(unique_counts)[0]}ä¸ªç›®æ ‡")


@click.command()
@click.argument("input_path", type=click.Path(exists=True))
@click.argument("output_dir", type=click.Path())
@click.option("--model", type=click.Path(exists=True), required=True,
              help="YOLOæ¨¡å‹æ–‡ä»¶è·¯å¾„ (.pt)")
@click.option("--conf-threshold", type=float, default=0.25,
              help="ç½®ä¿¡åº¦é˜ˆå€¼ (0.0-1.0)")
@click.option("--iou-threshold", type=float, default=0.45,
              help="IOUé˜ˆå€¼ (0.0-1.0)")
@click.option("--max-bbox-percent", type=float, default=10.0,
              help="æœ€å¤§è¾¹ç•Œæ¡†å æ¯” (%)")
@click.option("--device", type=click.Choice(["cpu", "cuda"]), default=None,
              help="è¿è¡Œè®¾å¤‡")
@click.option("--no-confidence", is_flag=True,
              help="ä¸æ˜¾ç¤ºç½®ä¿¡åº¦")
@click.option("--no-class-name", is_flag=True,
              help="ä¸æ˜¾ç¤ºç±»åˆ«åç§°")
def main(input_path, output_dir, model, conf_threshold, iou_threshold, 
         max_bbox_percent, device, no_confidence, no_class_name):
    """
    YOLOè°ƒè¯•å™¨ - åœ¨å›¾ç‰‡ä¸­æ ‡æ³¨YOLOè¯†åˆ«çš„æ–¹æ¡†å’Œç½®ä¿¡åº¦ç­‰ä¿¡æ¯
    
    è¾“å…¥ï¼šå›¾ç‰‡æˆ–è§†é¢‘æ–‡ä»¶
    è¾“å‡ºï¼šæ ‡æ³¨äº†YOLOè¯†åˆ«ç»“æœçš„å›¾ç‰‡
    
    ç¤ºä¾‹ï¼š
        python yolo_debugger.py input/video.mp4 output/ --model yolov8n.pt
        python yolo_debugger.py input/video.mp4 output/ --model custom_model.pt --conf-threshold 0.5
    """
    input_path = Path(input_path)
    output_dir = Path(output_dir)
    output_dir.mkdir(exist_ok=True, parents=True)
    
    # è®¾ç½®è®¾å¤‡
    if device is None:
        import torch
        device = "cuda" if torch.cuda.is_available() else "cpu"
    
    logger.info(f"è®¾å¤‡: {device}")
    logger.info(f"ç½®ä¿¡åº¦é˜ˆå€¼: {conf_threshold}")
    logger.info(f"IOUé˜ˆå€¼: {iou_threshold}")
    logger.info(f"æ˜¾ç¤ºç½®ä¿¡åº¦: {not no_confidence}")
    logger.info(f"æ˜¾ç¤ºç±»åˆ«åç§°: {not no_class_name}")
    
    # åŠ è½½YOLOæ¨¡å‹
    yolo_model = load_yolo_model(model, device)
    
    # åˆ¤æ–­è¾“å…¥ç±»å‹
    if input_path.suffix.lower() in ['.mp4', '.avi', '.mov', '.mkv', '.flv', '.wmv', '.webm']:
        # è§†é¢‘
        process_video(input_path, output_dir, yolo_model, conf_threshold, iou_threshold,
                     max_bbox_percent, not no_confidence, not no_class_name)
    else:
        # å›¾ç‰‡
        detection_info = process_image(input_path, output_dir, yolo_model,
                                      conf_threshold, iou_threshold, max_bbox_percent,
                                      not no_confidence, not no_class_name)
        
        if detection_info:
            with open(output_dir / "detection_info.json", 'w') as f:
                json.dump([detection_info], f, indent=2)
    
    logger.info(f"âœ… å®Œæˆï¼è¾“å‡ºç›®å½•: {output_dir}")
    logger.info(f"   - æ ‡æ³¨å›¾ç‰‡å·²ä¿å­˜åˆ°è¾“å‡ºç›®å½•")
    logger.info(f"   - masks/: æ£€æµ‹åˆ°çš„mask")
    logger.info(f"   - detection_info.json: æ£€æµ‹è¯¦ç»†ä¿¡æ¯")


if __name__ == "__main__":
    main()
