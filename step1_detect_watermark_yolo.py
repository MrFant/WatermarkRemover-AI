"""
ç¬¬ä¸€æ­¥ï¼šä½¿ç”¨ YOLO æ¨¡å‹æ£€æµ‹æ°´å°ä½ç½®å¹¶ç”Ÿæˆ mask
è¾“å…¥ï¼šå›¾ç‰‡æˆ–è§†é¢‘
è¾“å‡ºï¼šåŸå§‹å¸§ + maskæ–‡ä»¶

ä¼˜åŠ¿ï¼š
- é€Ÿåº¦å¿«ï¼ˆæ¯”Florenceå¿«5-10å€ï¼‰
- å¯ä»¥è‡ªå·±è®­ç»ƒæ¨¡å‹
- æ”¯æŒæœ¬åœ°æ¨¡å‹æ–‡ä»¶
"""

import sys
import click
import cv2
import numpy as np
from pathlib import Path
from PIL import Image
from loguru import logger
import tqdm
import json
import time

try:
    from ultralytics import YOLO
except ImportError:
    logger.error("æœªå®‰è£… ultralytics åº“ï¼Œè¯·è¿è¡Œ: pip install ultralytics")
    sys.exit(1)


def load_yolo_model(model_path, device='cuda'):
    """åŠ è½½YOLOæ¨¡å‹"""
    model_path = Path(model_path)
    
    if not model_path.exists():
        logger.error(f"æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨: {model_path}")
        sys.exit(1)
    
    logger.info(f"åŠ è½½YOLOæ¨¡å‹: {model_path}")
    start_time = time.time()
    
    try:
        model = YOLO(str(model_path))
        
        # è®¾ç½®è®¾å¤‡
        if device == 'cuda':
            model.to('cuda')
        else:
            model.to('cpu')
        
        load_time = time.time() - start_time
        logger.info(f"æ¨¡å‹åŠ è½½å®Œæˆ ({load_time:.2f}ç§’)")
        
        # æ˜¾ç¤ºæ¨¡å‹ä¿¡æ¯
        if hasattr(model, 'names'):
            logger.info(f"æ£€æµ‹ç±»åˆ«: {model.names}")
        
        return model
        
    except Exception as e:
        logger.error(f"åŠ è½½æ¨¡å‹å¤±è´¥: {e}")
        sys.exit(1)


def detect_watermark_with_yolo(image, model, conf_threshold=0.25, iou_threshold=0.45):
    """ä½¿ç”¨YOLOæ£€æµ‹æ°´å°"""
    # YOLOæ¨ç†
    results = model.predict(
        image,
        conf=conf_threshold,
        iou=iou_threshold,
        verbose=False
    )
    
    detections = []
    
    if results and len(results) > 0:
        result = results[0]
        
        # è·å–æ£€æµ‹æ¡†
        if result.boxes is not None:
            boxes = result.boxes.xyxy.cpu().numpy()  # [x1, y1, x2, y2]
            confs = result.boxes.conf.cpu().numpy()   # ç½®ä¿¡åº¦
            classes = result.boxes.cls.cpu().numpy()  # ç±»åˆ«
            
            for box, conf, cls in zip(boxes, confs, classes):
                x1, y1, x2, y2 = box
                detections.append({
                    'bbox': [int(x1), int(y1), int(x2), int(y2)],
                    'confidence': float(conf),
                    'class': int(cls),
                    'class_name': model.names[int(cls)] if hasattr(model, 'names') else str(int(cls))
                })
    
    return detections


def create_mask_from_detections(image_shape, detections, max_bbox_percent=10.0, expand_pixels=5):
    """ä»YOLOæ£€æµ‹ç»“æœåˆ›å»ºmask"""
    height, width = image_shape[:2]
    mask = np.zeros((height, width), dtype=np.uint8)
    
    if not detections:
        return mask
    
    image_area = width * height
    
    logger.debug(f"åˆ›å»ºmaskï¼Œæ£€æµ‹åˆ° {len(detections)} ä¸ªç›®æ ‡")
    
    for i, det in enumerate(detections):
        x1, y1, x2, y2 = det['bbox']
        bbox_area = (x2 - x1) * (y2 - y1)
        area_percent = (bbox_area / image_area) * 100
        
        logger.debug(f"  [{i+1}] {det['class_name']} (conf: {det['confidence']:.2f})")
        logger.debug(f"      ä½ç½®: ({x1}, {y1}) -> ({x2}, {y2})")
        logger.debug(f"      å æ¯”: {area_percent:.2f}%")
        
        # æ£€æŸ¥å¤§å°é™åˆ¶
        if area_percent <= max_bbox_percent:
            # æ‰©å±•è¾¹ç•Œ
            x1 = max(0, x1 - expand_pixels)
            y1 = max(0, y1 - expand_pixels)
            x2 = min(width, x2 + expand_pixels)
            y2 = min(height, y2 + expand_pixels)
            
            mask[y1:y2, x1:x2] = 255
            logger.debug(f"      âœ… å·²æ·»åŠ åˆ°mask")
        else:
            logger.warning(f"      âŒ è·³è¿‡ï¼ˆè¶…è¿‡æœ€å¤§å æ¯” {max_bbox_percent}%ï¼‰")
    
    # åå¤„ç†ï¼šè†¨èƒ€å’Œæ¨¡ç³Š
    if np.any(mask > 0):
        kernel = np.ones((3, 3), np.uint8)
        mask = cv2.dilate(mask, kernel, iterations=1)
        mask = cv2.GaussianBlur(mask, (5, 5), 0)
    
    return mask


def process_image(image_path, output_dir, model, conf_threshold, iou_threshold, max_bbox_percent, save_preview=True):
    """å¤„ç†å•å¼ å›¾ç‰‡"""
    logger.info(f"å¤„ç†å›¾ç‰‡: {image_path}")
    
    # è¯»å–å›¾ç‰‡
    image = cv2.imread(str(image_path))
    if image is None:
        logger.error(f"æ— æ³•è¯»å–å›¾ç‰‡: {image_path}")
        return None
    
    image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
    
    # æ£€æµ‹æ°´å°
    detections = detect_watermark_with_yolo(image_rgb, model, conf_threshold, iou_threshold)
    
    # åˆ›å»ºmask
    mask = create_mask_from_detections(image_rgb.shape, detections, max_bbox_percent)
    
    # ä¿å­˜
    frame_name = image_path.stem
    frames_dir = output_dir / "frames"
    masks_dir = output_dir / "masks"
    frames_dir.mkdir(exist_ok=True, parents=True)
    masks_dir.mkdir(exist_ok=True, parents=True)
    
    if save_preview:
        previews_dir = output_dir / "previews"
        previews_dir.mkdir(exist_ok=True, parents=True)
    
    cv2.imwrite(str(frames_dir / f"{frame_name}.png"), image)
    cv2.imwrite(str(masks_dir / f"{frame_name}.png"), mask)
    
    if save_preview:
        # ç”Ÿæˆæ ‡æ³¨å›¾ï¼ˆåœ¨åŸå›¾ä¸Šç»˜åˆ¶æ£€æµ‹æ¡†ä¸é®ç½©å åŠ ï¼‰
        annotated = image.copy()
        if detections:
            for det in detections:
                x1, y1, x2, y2 = det['bbox']
                cv2.rectangle(annotated, (x1, y1), (x2, y2), (0, 0, 255), 2)
                label = f"{det['class_name']} {det['confidence']:.2f}"
                cv2.putText(annotated, label, (x1, max(0, y1 - 5)), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 0, 255), 2, cv2.LINE_AA)
        if np.any(mask > 127):
            mask_color = np.zeros_like(annotated)
            mask_color[mask > 127] = (255, 0, 0)  # è“è‰²å åŠ åŒºåŸŸ
            annotated = cv2.addWeighted(annotated, 1.0, mask_color, 0.35, 0)
        
        cv2.imwrite(str(previews_dir / f"{frame_name}.png"), annotated)
    
    # ä¿å­˜æ£€æµ‹ä¿¡æ¯
    detection_info = {
        'frame': frame_name,
        'detections': detections,
        'mask_coverage': float(np.sum(mask > 127) / (mask.shape[0] * mask.shape[1]))
    }
    
    return detection_info


def process_video(video_path, output_dir, model, conf_threshold, iou_threshold, max_bbox_percent, 
                 use_first_frame_detection=False, min_mask_coverage=0.0, save_preview=True):
    """å¤„ç†è§†é¢‘"""
    logger.info(f"å¤„ç†è§†é¢‘: {video_path}")
    
    cap = cv2.VideoCapture(str(video_path))
    if not cap.isOpened():
        logger.error(f"æ— æ³•æ‰“å¼€è§†é¢‘: {video_path}")
        return
    
    # è·å–è§†é¢‘ä¿¡æ¯
    fps = cap.get(cv2.CAP_PROP_FPS)
    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
    
    logger.info(f"è§†é¢‘ä¿¡æ¯: {width}x{height}, {fps}fps, {total_frames}å¸§")
    
    # åˆ›å»ºè¾“å‡ºç›®å½•
    frames_dir = output_dir / "frames"
    masks_dir = output_dir / "masks"
    frames_dir.mkdir(exist_ok=True, parents=True)
    masks_dir.mkdir(exist_ok=True, parents=True)
    
    if save_preview:
        previews_dir = output_dir / "previews"
        previews_dir.mkdir(exist_ok=True, parents=True)
    
    # ä¿å­˜è§†é¢‘ä¿¡æ¯
    video_info = {
        'fps': fps,
        'width': width,
        'height': height,
        'total_frames': total_frames,
        'source_video': str(video_path),
        'detection_method': 'yolo'
    }
    
    with open(output_dir / "video_info.json", 'w') as f:
        json.dump(video_info, f, indent=2)
    
    # å¦‚æœä½¿ç”¨ç¬¬ä¸€å¸§æ£€æµ‹
    first_frame_mask = None
    first_frame_detections = None
    
    if use_first_frame_detection:
        logger.info("ğŸ” ä½¿ç”¨ç¬¬ä¸€å¸§æ£€æµ‹æ¨¡å¼ï¼ˆæ‰€æœ‰å¸§ä½¿ç”¨ç›¸åŒmaskï¼‰")
        ret, frame = cap.read()
        if ret:
            frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
            first_frame_detections = detect_watermark_with_yolo(
                frame_rgb, model, conf_threshold, iou_threshold
            )
            first_frame_mask = create_mask_from_detections(
                frame_rgb.shape, first_frame_detections, max_bbox_percent
            )
            logger.info(f"ç¬¬ä¸€å¸§æ£€æµ‹åˆ° {len(first_frame_detections)} ä¸ªç›®æ ‡")
        cap.set(cv2.CAP_PROP_POS_FRAMES, 0)
    else:
        logger.info("ğŸ” æ¯å¸§ç‹¬ç«‹æ£€æµ‹æ¨¡å¼")
    
    # å¤„ç†æ‰€æœ‰å¸§
    frame_count = 0
    detection_infos = []
    
    desc = "ä½¿ç”¨ç»Ÿä¸€æ£€æµ‹" if use_first_frame_detection else "é€å¸§æ£€æµ‹"
    
    with tqdm.tqdm(total=total_frames, desc=desc) as pbar:
        while cap.isOpened():
            ret, frame = cap.read()
            if not ret:
                break
            
            # è·å–mask
            if use_first_frame_detection and first_frame_mask is not None:
                mask = first_frame_mask
                detections = first_frame_detections
                filtered = False
            else:
                # æ¯å¸§ç‹¬ç«‹æ£€æµ‹
                frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
                detections = detect_watermark_with_yolo(
                    frame_rgb, model, conf_threshold, iou_threshold
                )
                mask = create_mask_from_detections(
                    frame_rgb.shape, detections, max_bbox_percent
                )
                
                # è®¡ç®—è¦†ç›–ç‡
                mask_coverage = float(np.sum(mask > 127) / (mask.shape[0] * mask.shape[1]))
                
                # è¿‡æ»¤ä½è¦†ç›–ç‡ï¼ˆå¯èƒ½æ˜¯è¯¯æ£€ï¼‰
                if min_mask_coverage > 0 and mask_coverage * 100 < min_mask_coverage:
                    mask = np.zeros_like(mask)
                    mask_coverage = 0.0
                    filtered = True
                else:
                    filtered = False
            
            # ä¿å­˜å¸§å’Œmask
            frame_name = f"frame_{frame_count:06d}"
            cv2.imwrite(str(frames_dir / f"{frame_name}.png"), frame)
            cv2.imwrite(str(masks_dir / f"{frame_name}.png"), mask)
            
            if save_preview:
                # ç”Ÿæˆæ ‡æ³¨å›¾ï¼ˆåœ¨åŸå›¾ä¸Šç»˜åˆ¶æ£€æµ‹æ¡†ä¸é®ç½©å åŠ ï¼‰
                annotated = frame.copy()
                if detections:
                    for det in detections:
                        x1, y1, x2, y2 = det['bbox']
                        cv2.rectangle(annotated, (x1, y1), (x2, y2), (0, 0, 255), 2)
                        label = f"{det['class_name']} {det['confidence']:.2f}"
                        cv2.putText(annotated, label, (x1, max(0, y1 - 5)), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 0, 255), 2, cv2.LINE_AA)
                if np.any(mask > 127):
                    mask_color = np.zeros_like(annotated)
                    mask_color[mask > 127] = (255, 0, 0)
                    annotated = cv2.addWeighted(annotated, 1.0, mask_color, 0.35, 0)
                
                cv2.imwrite(str(previews_dir / f"{frame_name}.png"), annotated)
            
            # è®°å½•æ£€æµ‹ä¿¡æ¯
            detection_info = {
                'frame': frame_name,
                'frame_index': frame_count,
                'num_detections': len(detections) if detections else 0,
                'mask_coverage': float(np.sum(mask > 127) / (mask.shape[0] * mask.shape[1])),
                'using_first_frame': use_first_frame_detection,
                'filtered': filtered if not use_first_frame_detection else False
            }
            
            detection_infos.append(detection_info)
            
            frame_count += 1
            pbar.update(1)
    
    cap.release()
    
    # ä¿å­˜æ£€æµ‹ä¿¡æ¯
    with open(output_dir / "detection_info.json", 'w') as f:
        json.dump(detection_infos, f, indent=2)
    
    # ç»Ÿè®¡ä¿¡æ¯
    logger.info(f"\nâœ… å®Œæˆï¼å…±å¤„ç† {frame_count} å¸§")
    logger.info(f"ğŸ“ å¸§ä¿å­˜åˆ°: {frames_dir}")
    logger.info(f"ğŸ“ Maskä¿å­˜åˆ°: {masks_dir}")
    if save_preview:
        logger.info(f"ğŸ“ é¢„è§ˆä¿å­˜åˆ°: {previews_dir}")
    
    # è¾“å‡ºç»Ÿè®¡
    if not use_first_frame_detection:
        logger.info("\nğŸ“Š æ£€æµ‹ç»Ÿè®¡:")
        
        coverages = [info['mask_coverage'] for info in detection_infos]
        avg_coverage = sum(coverages) / len(coverages) if coverages else 0
        
        logger.info(f"  å¹³å‡maskè¦†ç›–: {avg_coverage*100:.2f}%")
        
        if min_mask_coverage > 0:
            filtered_count = sum(1 for info in detection_infos if info.get('filtered', False))
            if filtered_count > 0:
                logger.info(f"  ğŸ” è¿‡æ»¤çš„å¸§: {filtered_count}")
        
        num_detections = [info['num_detections'] for info in detection_infos]
        unique_counts = set(num_detections)
        
        if len(unique_counts) > 1:
            logger.warning(f"  âš ï¸  æ£€æµ‹æ•°é‡ä¸ä¸€è‡´:")
            for count in sorted(unique_counts):
                frames_with_count = sum(1 for n in num_detections if n == count)
                logger.warning(f"     {count}ä¸ªç›®æ ‡: {frames_with_count}å¸§")
        else:
            logger.info(f"  âœ… æ‰€æœ‰å¸§æ£€æµ‹ä¸€è‡´: {list(unique_counts)[0]}ä¸ªç›®æ ‡")


@click.command()
@click.argument("input_path", type=click.Path(exists=True))
@click.argument("output_dir", type=click.Path())
@click.option("--model", type=click.Path(exists=True), required=True,
              help="YOLOæ¨¡å‹æ–‡ä»¶è·¯å¾„ (.pt)")
@click.option("--conf-threshold", type=float, default=0.25,
              help="ç½®ä¿¡åº¦é˜ˆå€¼ (0.0-1.0)")
@click.option("--iou-threshold", type=float, default=0.45,
              help="IOUé˜ˆå€¼ (0.0-1.0)")
@click.option("--max-bbox-percent", type=float, default=10.0,
              help="æœ€å¤§è¾¹ç•Œæ¡†å æ¯” (%)")
@click.option("--device", type=click.Choice(["cpu", "cuda"]), default=None,
              help="è¿è¡Œè®¾å¤‡")
@click.option("--use-first-frame/--detect-each-frame", default=False,
              help="è§†é¢‘æ˜¯å¦ä½¿ç”¨ç¬¬ä¸€å¸§æ£€æµ‹ï¼ˆé»˜è®¤æ¯å¸§æ£€æµ‹ï¼‰")
@click.option("--min-mask-coverage", type=float, default=0.0,
              help="æœ€å°maskè¦†ç›–ç‡ (%%)ï¼Œä½äºæ­¤å€¼ä½¿ç”¨ç©ºmask")
def main(input_path, output_dir, model, conf_threshold, iou_threshold, 
         max_bbox_percent, device, use_first_frame, min_mask_coverage):
    """
    ç¬¬ä¸€æ­¥ï¼šä½¿ç”¨YOLOæ£€æµ‹æ°´å°ä½ç½®å¹¶ç”Ÿæˆmask
    
    è¾“å…¥ï¼šå›¾ç‰‡æˆ–è§†é¢‘æ–‡ä»¶
    è¾“å‡ºï¼šframes/ ç›®å½•ï¼ˆåŸå§‹å¸§ï¼‰+ masks/ ç›®å½•ï¼ˆmaskï¼‰
    
    ç¤ºä¾‹ï¼š
        python step1_detect_watermark_yolo.py input/video.mp4 output/ --model yolov8n.pt
        python step1_detect_watermark_yolo.py input/video.mp4 output/ --model custom_model.pt --conf-threshold 0.5
    """
    input_path = Path(input_path)
    output_dir = Path(output_dir)
    output_dir.mkdir(exist_ok=True, parents=True)
    
    # è®¾ç½®è®¾å¤‡
    if device is None:
        import torch
        device = "cuda" if torch.cuda.is_available() else "cpu"
    
    logger.info(f"è®¾å¤‡: {device}")
    logger.info(f"ç½®ä¿¡åº¦é˜ˆå€¼: {conf_threshold}")
    logger.info(f"IOUé˜ˆå€¼: {iou_threshold}")
    
    # åŠ è½½YOLOæ¨¡å‹
    yolo_model = load_yolo_model(model, device)
    
    # åˆ¤æ–­è¾“å…¥ç±»å‹
    if input_path.suffix.lower() in ['.mp4', '.avi', '.mov', '.mkv', '.flv', '.wmv', '.webm']:
        # è§†é¢‘
        process_video(input_path, output_dir, yolo_model, conf_threshold, iou_threshold,
                     max_bbox_percent, use_first_frame, min_mask_coverage)
    else:
        # å›¾ç‰‡
        detection_info = process_image(input_path, output_dir, yolo_model,
                                      conf_threshold, iou_threshold, max_bbox_percent)
        
        if detection_info:
            with open(output_dir / "detection_info.json", 'w') as f:
                json.dump([detection_info], f, indent=2)
    
    logger.info(f"âœ… å®Œæˆï¼è¾“å‡ºç›®å½•: {output_dir}")
    logger.info(f"   - frames/: åŸå§‹å¸§")
    logger.info(f"   - masks/: æ£€æµ‹åˆ°çš„mask")
    logger.info(f"   - detection_info.json: æ£€æµ‹è¯¦ç»†ä¿¡æ¯")


if __name__ == "__main__":
    main()

